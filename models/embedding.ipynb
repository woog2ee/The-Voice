{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "407c7412",
   "metadata": {},
   "source": [
    "### 기본 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4037c7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Korean Sentence Splitter]: Initializing Kss...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import ast\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from kss import split_sentences\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b0c7a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8678c3d7",
   "metadata": {},
   "source": [
    "### 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb832058",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original    = pd.read_csv('./dataset/사건원문.csv')\n",
    "df_kor_ratio5  = pd.read_csv('./dataset/한글태그_5%적용.csv')\n",
    "df_kor_ratio10 = pd.read_csv('./dataset/한글태그_10%적용.csv')\n",
    "df_eng_ratio5  = pd.read_csv('./dataset/영어태그_5%적용.csv')\n",
    "df_eng_ratio10 = pd.read_csv('./dataset/영어태그_10%적용.csv')\n",
    "\n",
    "datanames = ['original', 'kor_ratio5', 'kor_ratio10', 'eng_ratio5', 'eng_ratio10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fab0eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문자열의 리스트화\n",
    "def str2list(textdata, attribute):\n",
    "    textdata = [ast.literal_eval(case) for case in textdata[attribute]]\n",
    "    return textdata\n",
    "\n",
    "\n",
    "# 데이터프레임 내용 리스트화\n",
    "for dataname in datanames:\n",
    "    rawdataframe = globals()[f'df_{dataname}']\n",
    "    globals()[f'{dataname}_content'] = str2list(rawdataframe, '내용')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38ec50a",
   "metadata": {},
   "source": [
    "### ngram 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fd9566d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 content를 ngram 리스트로 변환\n",
    "def content2ngram(content, n):\n",
    "    \"\"\"\n",
    "        content: 사건 내용 리스트 \n",
    "        n: ngram으로 자를 단위\n",
    "    \"\"\"\n",
    "    ngram_list = []     # 전체 텍스트 ngram\n",
    "    for case in content:\n",
    "        cut_count = len(case)-n     # ngram으로 자를 횟수\n",
    "        ngram_case = []             # 사건당 ngram\n",
    "        \n",
    "        for i in range(cut_count):\n",
    "            ngram_group = ''     # 합쳐질 ngram\n",
    "            for j in range(n):\n",
    "                if j != 0: ngram_group += ' '\n",
    "                ngram_group += case[i+j]     # 문장 합쳐서 붙임\n",
    "            ngram_case.append(ngram_group)\n",
    "        ngram_list.append(ngram_case)\n",
    "    return ngram_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf242945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 ngram 변환\n",
    "for dataname in datanames:\n",
    "    rawdata = globals()[f'{dataname}_content']\n",
    "    for n in [2, 3, 4]:\n",
    "        globals()[f'{dataname}_content_{n}gram'] = content2ngram(rawdata, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f442f9a7",
   "metadata": {},
   "source": [
    "### sentence transformer 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "588741a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceTagger:\n",
    "    def __init__(self):\n",
    "        self.device = torch.device('cuda')\n",
    "        self.embedding_model = None\n",
    "\n",
    "        \n",
    "    # SentenceTransformer 모델 로드\n",
    "    def set_model(self):\n",
    "        self.embedding_model = SentenceTransformer('../dacon/news_topic_classification/KoSentenceBERT_SKTBERT/output/training_con',\n",
    "                                                   device=self.device)\n",
    "\n",
    "    # 전체에서 사건별 임베딩\n",
    "    def sentence_embedding(self, content):\n",
    "        content_embedding = []     # 전체 임베딩\n",
    "        for case in content:\n",
    "            case_embedding = []     # 사건별 임베딩\n",
    "            for sent in case:\n",
    "                sent_embedding = self.embedding_model.encode(sent, device=self.device)     # 문장별 임베딩\n",
    "                case_embedding.append(np.array(sent_embedding, dtype=object))\n",
    "            content_embedding.append(np.array(case_embedding, dtype=object))\n",
    "        return np.array(content_embedding, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20ad32a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "Load Model\n"
     ]
    }
   ],
   "source": [
    "# 문장 임베딩 객체 생성\n",
    "sent_tagger = SentenceTagger()\n",
    "sent_tagger.set_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "feb4d73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 ngram별 임베딩\n",
    "for dataname in datanames:\n",
    "    for n in [2, 3, 4]:\n",
    "        cur_content_ngram = globals()[f'{dataname}_content_{n}gram']\n",
    "        globals()[f'{dataname}_{n}gram_embedding'] = sent_tagger.sentence_embedding(cur_content_ngram)\n",
    "        #print(f' {dataname} {n}gram embedding finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d973e311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 ngram별 임베딩 저장\n",
    "for dataname in datanames:\n",
    "    for n in [2, 3, 4]:\n",
    "        cur_ngram_embedding = globals()[f'{dataname}_{n}gram_embedding']\n",
    "        np.save(f'./save_embeddings/{dataname}_{n}gram_embedding.npy', np.array(cur_ngram_embedding, dtype=object))\n",
    "        #print(f' {dataname} {n}gram embedding saved')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kosentence",
   "language": "python",
   "name": "kosentence"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
